{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPyDGFVIamok3LrECcl5UAD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":7,"metadata":{"id":"G_XCLvYun2cH","executionInfo":{"status":"ok","timestamp":1670373879466,"user_tz":-540,"elapsed":15913,"user":{"displayName":"Chan IL Hwang","userId":"16733896246709433089"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e1cd1410-a3ec-4fe3-f815-d0c891201e0e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","import matplotlib.pylab as plt\n","\n","from keras.datasets import mnist\n","from keras.models import Sequential, Model\n","from keras.utils import to_categorical\n","from keras.layers import SimpleRNN, Dense, Flatten, LSTM, Reshape, Conv2D, MaxPooling2D, Input, Dropout\n","from keras.optimizers import Adam\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","n_output = 784\n","n_noise = 128\n","\n","generator = Sequential()\n","generator.add(Dense(units = 256, input_dim = n_noise, activation = 'relu'))\n","generator.add(Dense(units = 512, activation = 'relu'))\n","generator.add(Dense(units = n_output, activation = 'tanh'))\n","\n","discriminator = Sequential()\n","discriminator.add(Dense(256, input_dim = n_output, activation = 'relu'))\n","discriminator.add(Dropout(0.3))\n","discriminator.add(Dense(1, activation = 'sigmoid'))"]},{"cell_type":"code","source":["g_input = Input(shape = (n_noise, ))\n","g_output = discriminator(generator(g_input))\n","gan = Model(g_input, g_output)\n","\n","discriminator.trainable = True\n","adam = tf.optimizers.Adam(learning_rate = 0.0002, beta_1 = 0.5)\n","discriminator.compile(loss = 'binary_crossentropy', optimizer = adam)\n","\n","discriminator.trainable = False\n","gan.compile(loss = 'binary_crossentropy', optimizer = adam)\n","\n","gan.summary()\n"],"metadata":{"id":"UIFw1Gkrrgzq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670373883486,"user_tz":-540,"elapsed":6,"user":{"displayName":"Chan IL Hwang","userId":"16733896246709433089"}},"outputId":"f7317d2d-3b9e-462f-e5a6-dd2a33a0bb0c"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_4 (InputLayer)        [(None, 128)]             0         \n","                                                                 \n"," sequential_4 (Sequential)   (None, 784)               566800    \n","                                                                 \n"," sequential_5 (Sequential)   (None, 1)                 201217    \n","                                                                 \n","=================================================================\n","Total params: 768,017\n","Trainable params: 566,800\n","Non-trainable params: 201,217\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["n_epoch = 100\n","batch_size = 128\n","Saving_interval = 10\n","\n","(train_images, _), (_, _) = mnist.load_data()\n","n_images = len(train_images)\n","train_images = train_images.reshape((n_images, n_output))\n","train_images = (train_images - 127.5) / 127.5\n","\n","train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(n_images).batch(batch_size)\n","\n","for i in range(n_epoch):\n","  print(\"Epoch Num : {}/{}\".format((i+1), n_epoch))\n","  for image_batch in train_dataset:\n","    n_bt_imgs = len(image_batch)\n","    true_labels = np.ones((n_bt_imgs, 1))\n","    fake_labels = np.zeros((n_bt_imgs, 1))\n","    d_loss_real = discriminator.train_on_batch(image_batch, true_labels)\n","\n","    noise = np.random.normal(0, 1, (n_bt_imgs, n_noise))\n","    gen_imgs = generator.predict(noise)\n","    d_loss_fake = discriminator.train_on_batch(gen_imgs, fake_labels)\n","\n","    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","    #gan 모델 학습 \n","    g_loss = gan.train_on_batch(noise, true_labels)\n","    \n","  if (i + 1) % Saving_interval == 0 or i == 0:\n","    print('Epoch : %d' % (i + 1), 'd_loss : %.4f' % d_loss, 'g_loss : %.4f' % g_loss)\n","    noise = np.random.normal(0, 1, (25, n_noise))\n","    gen_imgs = generator.predict(noise)\n","    gen_imgs = 0.5 * gen_imgs + 0.5\n","    fig, axs = plt.subplots(5, 5)\n","    count = 0\n","    for j in range(5):\n","      for k in range(5):\n","        axs[j, k].imshow(np.reshape((gen_imgs[count]), (28, 28)))\n","        axs[j, k].axis('off')\n","        count += 1\n","    plt.show()\n","    fig.savefig(\"/content/gdrive/My Drive/gan_results/g_mnist_%d.png\"%(i+1)) "],"metadata":{"id":"Wg3R5LKBxIr9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from PIL import Image\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow_hub as hub\n","import functools\n","import os\n","\n","#load image\n","def load_image(image_path):\n","  image = tf.io.read_file(image_path)\n","  image = tf.image.decode_image(image, channels=3)\n","  image = tf.image.convert_image_dtype(image, tf.float32)\n","  image = tf.image.resize(image, (256,256))\n","  image = image[tf.newaxis,:] \n","  return image\n","\n","def tensor2image(image):\n","  image = image*255.0\n","  image = np.array(image, dtype=np.uint8)\n","  return Image.fromarray(image)\n","\n","content_image = load_image('/content/gdrive/My Drive/content1.png')\n","style_image = load_image('/content/gdrive/My Drive/style1.jpg')\n","\n","hub_module = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')\n","stylized_image = hub_module(tf.constant(content_image), tf.constant(style_image))[0][0]\n","#stylized_image = outputs[0][0]\n","\n","final_image = tensor2image(stylized_image)\n","if final_image.mode != 'RGB':\n","    final_image = final_image.convert('RGB')\n","final_image.save('/content/gdrive/My Drive/stylized_image1.jpg')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":400},"id":"BA6cjL8FGJwS","executionInfo":{"status":"error","timestamp":1670375388164,"user_tz":-540,"elapsed":320,"user":{"displayName":"Chan IL Hwang","userId":"16733896246709433089"}},"outputId":"ee701b68-e06f-4358-b833-dcd4ff56ba19"},"execution_count":18,"outputs":[{"output_type":"error","ename":"NotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-bf09f4a7ae15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mcontent_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/My Drive/content1.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mstyle_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/My Drive/style1.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-18-bf09f4a7ae15>\u001b[0m in \u001b[0;36mload_image\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#load image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_image_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/io_ops.py\u001b[0m in \u001b[0;36mread_file\u001b[0;34m(filename, name)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0mof\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m\"string\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfile\u001b[0m \u001b[0mcontents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   \"\"\"\n\u001b[0;32m--> 133\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_io_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36mread_file\u001b[0;34m(filename, name)\u001b[0m\n\u001b[1;32m    564\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m       return read_file_eager_fallback(\n\u001b[0m\u001b[1;32m    567\u001b[0m           filename, name=name, ctx=_ctx)\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36mread_file_eager_fallback\u001b[0;34m(filename, name, ctx)\u001b[0m\n\u001b[1;32m    587\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m   _result = _execute.execute(b\"ReadFile\", 1, inputs=_inputs_flat,\n\u001b[0m\u001b[1;32m    590\u001b[0m                              attrs=_attrs, ctx=ctx, name=name)\n\u001b[1;32m    591\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFoundError\u001b[0m: /content/gdrive/My Drive/content1.png; No such file or directory [Op:ReadFile]"]}]}]}